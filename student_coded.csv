doc_type,participant_id,subject_codes,semesters,role,summary,familiarity_level,usage_frequency,primary_use_case,critical_evaluation_skill,ethical_confidence,perceived_impact_on_learning,key_themes,integration_depth,observed_student_use_pattern,observed_critical_evaluation,primary_ethics_concern,perception_of_learning_impact
student,AUT-S01,31266,Autumn,student,"This student uses generative AI sparingly, mainly within group work and tutorial activities, and prefers traditional research methods like Google and reading sources directly. They see AI as useful for quickly gaining a surface-level overview and scaffolding answers but distrust it for deeper understanding and are consistently sceptical about its accuracy. They systematically verify AI outputs against other sources and often find them too general, requiring additional ‘old-fashioned’ research. They feel institutionally well informed about what tools are allowed but still want clearer, easily accessible guidance on where the ethical and policy boundaries lie, especially around plagiarism in group work.",medium,light,scaffolding and overview for group/tutorial questions,systematic checking,somewhat clear,mixed,"['preference for traditional learning methods', 'speed and efficiency', 'concerns about accuracy', 'systematic verification of AI outputs', 'over-reliance risk in group work', 'need for clearer AI use and plagiarism guidelines', 'surface-level understanding versus deep learning', 'tool-specific policy awareness (Copilot allowed, others restricted)']",,,,,
student,AUT-S02,31266;31269,Autumn;Spring,student,"This student uses generative AI regularly as a support tool for understanding, structuring assignments, and handling practical tasks like pivot tables and presentation design, but not as a full content generator. They feel institutional policies are clear and easy to follow, yet still grapple with how to use AI effectively without undermining their own learning or breaching ethical boundaries. They describe AI as a time-saver that can also feel like “cheating” and potentially make a degree redundant if overused, so they try to combine it with their own research and intuition. They would like more in-class, task-specific guidance on different AI tools and business-relevant applications.",high,moderate,checking answers and structuring work,occasional checking,somewhat clear,mixed,"['speed and efficiency', 'concerns about over-reliance', 'mixed feelings about learning benefits', 'clarity of institutional policies', 'case-by-case critical evaluation', 'desire for task-specific in-class guidance', 'business and real-world application of AI tools']",,,,,
student,SPR-S01,31269,Spring,student,"This student is an experienced and enthusiastic generative AI user who integrates tools like ChatGPT and Copilot into both study and personal life, mainly to handle groundwork such as extracting criteria, summarising case studies, planning workloads, and generating presentation materials. They deliberately avoid using AI for core critical thinking or essay writing, emphasising authenticity, learning, and proper referencing. They systematically cross-check AI outputs, treat the tool like a fallible assistant, and feel BRM reinforced ethical and transparent use. While strongly positive about AI’s efficiency benefits, they are concerned about peers becoming over‑reliant and losing independent critical thinking skills.",high,heavy,groundwork and study planning,systematic checking,very clear,strongly positive,"['groundwork and efficiency', 'clear separation between AI support and own thinking', 'systematic cross-checking and handling hallucinations', 'importance of transparency and referencing AI', 'desire for consistent and faculty-specific AI policies', 'concerns about over-reliance and loss of critical thinking', 'degree-specific strengths and weaknesses of AI', 'integration of AI into coursework as a comparative tool']",,,,,
student,SPR-S02,31269,Spring,student,"This student is a highly experienced AI user who relies on tools like ChatGPT and Copilot to make coursework more efficient, especially for summarising briefs, clarifying questions, generating diagrams and scripts, and double-checking their own work. They consistently frame AI as a supportive tool rather than a replacement for learning, and are concerned that others may become lazy or lose essential skills if they over-rely on it. They systematically verify AI outputs, particularly statistics and links, and feel institution and subject policies about ethical use are clear, though they are unsure whether the subject specifically improved their ethical decision-making. Overall, they see AI as strongly beneficial when used critically and responsibly.",high,heavy,checking answers,systematic checking,very clear,strongly positive,"['speed and efficiency', 'use as a tool not a replacement', 'concerns about accuracy', 'systematic verification of statistics and sources', 'over-reliance risk and student laziness', 'preference for ChatGPT over Copilot', 'clear institutional guidance and appendices', 'value of AI-integrated activities for comparison and reflection']",,,,,
student,SPR-S03,31269,Spring,student,"This student is a confident, experienced user of LLMs who mainly relies on them to clarify concepts, condense case studies, and compare or check their own work rather than to generate full answers. They are highly aware of hallucinations and routinely cross-check AI outputs with external sources, sometimes investing significant time to verify claims. They see AI as strongly beneficial for learning and confidence when used after doing their own thinking, but are concerned about peers becoming dependent on AI and losing problem-solving skills. They feel their BRM subject significantly improved their ethical awareness and prefer AI to be integrated as a comparative, fact-checking tool with clearer limits on how much use is acceptable.",high,moderate,checking answers,systematic checking,very clear,strongly positive,"['use of AI for summarising and clarifying complex material', 'AI as a comparative tool after completing own work', 'concerns about accuracy and hallucinations', 'time-consuming but deliberate verification and cross-referencing', 'over-reliance risk and loss of independent problem solving', 'positive impact of subject design on ethical AI use', 'desire for clearer guidance on acceptable extent of AI use', 'trust in AI for learning but not for final judgment']",,,,,
